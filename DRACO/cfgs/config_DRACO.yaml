trainer:
  gpus: -1
  distributed_backend: "dp"
  accumulate_grad_batches: 4
  profiler: False
  max_epochs: 12
  # amp_level: "02"
  # precision: 16

scheduler:
  type: MultiStepLR
  args: 
    milestones: [5, 7, 9] #[6, 8, 18]
    gamma: 0.1

dataset:
  train:
    type: MultiView_canonical_dataset_blender
    args: 
      dataset_path: "../data/DRACO20K_cars/" # "../data/sunny_cars/"
      num_views: 3
      train: 1
      normalize: True
      gt_depth: False
      jitter: True
      canonical: True
      gt_nocs: False

    loader:
      args:
        batch_size: 3
        num_workers: 8
        shuffle: True
        drop_last: True

  val:
    type: MultiView_canonical_dataset_blender
    args: 
      dataset_path: "../data/DRACO20K_cars/" # "../data/sunny_cars/"
      num_views: 3
      train: 1
      normalize: True
      gt_depth: False
      jitter: False
      canonical: True
      gt_nocs: False

    loader:
      args:
        batch_size: 3
        num_workers: 8
        shuffle: False
        drop_last: True

loss:
  geometric:
    type: Geometric_loss
    weight: 0.001
  photometric:
    type: Photometric_loss
    weight: 1.0
    args:
      alpha: 0.15
  smoothness:
    type: Smoothness_loss
    weight: 0.05
  mask:
    type: torch.nn.BCELoss
    weight: 0.3 

utils:
  depth_scale: 10

model:
  file: resnet
  type: ResNetUNet50 
  args:
    pretrained: True

optimizer:
  type: Adam
  args:
    lr: 5e-5

callback:
  model_checkpoint:
    depth:
      type: pl.callbacks.ModelCheckpoint
      args:
        filename: "model-{epoch}-{val_loss:.4f}-depth"
        monitor: "val_loss"
        dirpath: "./checkpoints"
        save_top_k: 1
    nocs:
      type: pl.callbacks.ModelCheckpoint
      args:
        filename: "model-{epoch}-{val_loss:.4f}-nocs_and_depth"
        dirpath: "./checkpoints_nocs_and_depth"
        monitor: "val_loss"
        save_top_k: 1
    
